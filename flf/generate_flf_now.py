#!/usr/bin/env python3
"""
Generate FLF video NOW with different parameters
"""

import json
import requests
import time
import os
import random

COMFYUI_URL = "http://localhost:8188"

def upload_image(path):
    """Upload image to ComfyUI"""
    with open(path, 'rb') as f:
        files = {"image": (os.path.basename(path), f, "image/jpeg")}
        response = requests.post(f"{COMFYUI_URL}/upload/image", files=files)
        return response.json().get("name")

print("ğŸ¬ FLFå‹•ç”»ç”Ÿæˆé–‹å§‹ï¼")
print("="*50)

# Check ComfyUI
try:
    response = requests.get(f"{COMFYUI_URL}/system_stats")
    print("âœ… ComfyUIç¨¼åƒä¸­")
except:
    print("âŒ ComfyUI not accessible")
    exit(1)

# Upload images - ç•°ãªã‚‹ç”»åƒã®çµ„ã¿åˆã‚ã›ã‚‚è©¦ã›ã¾ã™
print("ğŸ“¤ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
start_img = upload_image("/home/kazuph/runpod-wan2.2-api/rapid-i2v/input/girl2.jpg")  # é€†ã«ã—ã¦ã¿ã‚‹
end_img = upload_image("/home/kazuph/runpod-wan2.2-api/rapid-i2v/input/girl1.jpg")

seed = random.randint(100, 999)
print(f"ğŸ² Seed: {seed}")

# FLF workflow with WanFirstLastFrameToVideo
workflow = {
    "1": {
        "inputs": {
            "ckpt_name": "wan2.2-i2v-rapid-aio.safetensors"
        },
        "class_type": "CheckpointLoaderSimple"
    },
    "2": {
        "inputs": {
            "image": start_img,
            "upload": "image"
        },
        "class_type": "LoadImage"
    },
    "3": {
        "inputs": {
            "image": end_img,
            "upload": "image"
        },
        "class_type": "LoadImage"
    },
    "4": {
        "inputs": {
            "text": "beautiful smooth morphing transition between two female faces, gradual transformation, cinematic quality, natural movement",
            "clip": ["1", 1]
        },
        "class_type": "CLIPTextEncode"
    },
    "5": {
        "inputs": {
            "text": "static, blurry, distortion, abrupt change, low quality, artifacts, mouth opening, talking",
            "clip": ["1", 1]
        },
        "class_type": "CLIPTextEncode"
    },
    "6": {
        "inputs": {
            "positive": ["4", 0],
            "negative": ["5", 0],
            "vae": ["1", 2],
            "start_image": ["2", 0],
            "end_image": ["3", 0],
            "width": 576,  # å°‘ã—å¤§ãã
            "height": 576,
            "length": 49,  # ç´„2ç§’
            "batch_size": 1
        },
        "class_type": "WanFirstLastFrameToVideo"
    },
    "7": {
        "inputs": {
            "model": ["1", 0],
            "positive": ["6", 0],
            "negative": ["6", 1],
            "latent_image": ["6", 2],
            "seed": seed,
            "steps": 8,  # ã‚‚ã†å°‘ã—ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¢—ã‚„ã™
            "cfg": 2.0,  # CFGã‚‚èª¿æ•´
            "sampler_name": "lcm",
            "scheduler": "beta",
            "denoise": 1.0
        },
        "class_type": "KSampler"
    },
    "8": {
        "inputs": {
            "samples": ["7", 0],
            "vae": ["1", 2]
        },
        "class_type": "VAEDecode"
    },
    "9": {
        "inputs": {
            "images": ["8", 0],
            "filename_prefix": f"flf_morph_{seed}"
        },
        "class_type": "SaveImage"
    }
}

print("ğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€ä¿¡ä¸­...")
print(f"  è§£åƒåº¦: 576x576")
print(f"  ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: 49 (ç´„2ç§’)")
print(f"  ã‚¹ãƒ†ãƒƒãƒ—æ•°: 8")

response = requests.post(f"{COMFYUI_URL}/prompt", json={"prompt": workflow})
result = response.json()

prompt_id = result.get("prompt_id")
if not prompt_id:
    print(f"âŒ Failed: {result}")
    exit(1)

print(f"ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆID: {prompt_id}")
print("â³ å‡¦ç†ä¸­...")

# Wait for completion
start_time = time.time()
while time.time() - start_time < 120:  # 2åˆ†ã¾ã§å¾…ã¤
    history = requests.get(f"{COMFYUI_URL}/history/{prompt_id}").json()
    
    if prompt_id in history:
        if "outputs" in history[prompt_id]:
            elapsed = time.time()-start_time
            print(f"\nâœ… å®Œäº†ï¼å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’")
            
            outputs = history[prompt_id]["outputs"]
            images = []
            for node_id, output in outputs.items():
                if "images" in output:
                    for img in output["images"]:
                        images.append(img['filename'])
            
            if images:
                print(f"ğŸ“¹ ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(images)}")
                
                # Create video
                output_dir = "/home/kazuph/runpod-wan2.2-api/comfyui_workflow/output"
                video_output = f"/home/kazuph/runpod-wan2.2-api/flf/output/flf_morph_{seed}.mp4"
                
                # Use first image name pattern
                pattern = images[0].replace("00001", "%05d")
                
                cmd = f"ffmpeg -framerate 24 -pattern_type sequence -start_number 1 -i '{output_dir}/{pattern}' -c:v libx264 -pix_fmt yuv420p -crf 19 {video_output} -y 2>/dev/null"
                
                if os.system(cmd) == 0:
                    if os.path.exists(video_output):
                        size_kb = os.path.getsize(video_output) / 1024
                        print(f"\nğŸ‰ å‹•ç”»ç”ŸæˆæˆåŠŸï¼")
                        print(f"ğŸ“ å ´æ‰€: {video_output}")
                        print(f"ğŸ“Š ã‚µã‚¤ã‚º: {size_kb:.1f} KB")
                    else:
                        print(f"âš ï¸ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                else:
                    print(f"âš ï¸ ffmpegå¤‰æ›ã«å¤±æ•—")
            
            exit(0)
        
        if "status" in history[prompt_id]:
            status = history[prompt_id]["status"]
            if status.get("status_str") == "error":
                print(f"\nâŒ Error: {status}")
                exit(1)
    
    print(".", end="", flush=True)
    time.sleep(2)

print("\nâŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
exit(1)