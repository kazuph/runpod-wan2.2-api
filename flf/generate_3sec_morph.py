#!/usr/bin/env python3
"""
3ç§’ã®ã‚†ã£ãã‚Šã¨ã—ãŸåˆ¥äººã¸ã®å¤‰åŒ–å‹•ç”»ã‚’ç”Ÿæˆ
"""

import json
import requests
import time
import os
import random

COMFYUI_URL = "http://localhost:8188"

def upload_image(path):
    """Upload image to ComfyUI"""
    with open(path, 'rb') as f:
        files = {"image": (os.path.basename(path), f, "image/jpeg")}
        response = requests.post(f"{COMFYUI_URL}/upload/image", files=files)
        return response.json().get("name")

print("ğŸ¬ 3ç§’é–“ã®äººç‰©å¤‰åŒ–å‹•ç”»ç”Ÿæˆ")
print("="*60)

# Check ComfyUI
try:
    response = requests.get(f"{COMFYUI_URL}/system_stats")
    print("âœ… ComfyUIç¨¼åƒä¸­")
except:
    print("âŒ ComfyUI not accessible")
    exit(1)

# Upload images
print("ğŸ“¤ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
start_img = upload_image("/home/kazuph/runpod-wan2.2-api/rapid-i2v/input/girl1.jpg")
end_img = upload_image("/home/kazuph/runpod-wan2.2-api/rapid-i2v/input/girl2.jpg")
print(f"  é–‹å§‹: {start_img}")
print(f"  çµ‚äº†: {end_img}")

seed = random.randint(1000, 9999)
print(f"ğŸ² Seed: {seed}")

# 3ç§’ = 72ãƒ•ãƒ¬ãƒ¼ãƒ  (24fps)
workflow = {
    "1": {
        "inputs": {
            "ckpt_name": "wan2.2-i2v-rapid-aio.safetensors"
        },
        "class_type": "CheckpointLoaderSimple"
    },
    "2": {
        "inputs": {
            "image": start_img,
            "upload": "image"
        },
        "class_type": "LoadImage"
    },
    "3": {
        "inputs": {
            "image": end_img,
            "upload": "image"
        },
        "class_type": "LoadImage"
    },
    "4": {
        "inputs": {
            "text": """Gradual metamorphosis from one person to completely different person over 3 seconds. 
            Slow facial feature transformation: eyes gradually changing shape and color, 
            nose reshaping smoothly, mouth and lips morphing to different form, 
            hair style and color transitioning naturally, skin tone shifting gradually,
            bone structure evolving, identity changing progressively frame by frame,
            seamless blend between two different individuals, cinematic quality morphing effect""",
            "clip": ["1", 1]
        },
        "class_type": "CLIPTextEncode"
    },
    "5": {
        "inputs": {
            "text": """static image, no change, sudden jump, instant transformation, 
            flickering, glitchy transition, unnatural morphing, distorted faces,
            blurry, low quality, artifacts, mouth opening, talking, lips moving""",
            "clip": ["1", 1]
        },
        "class_type": "CLIPTextEncode"
    },
    "6": {
        "inputs": {
            "positive": ["4", 0],
            "negative": ["5", 0],
            "vae": ["1", 2],
            "start_image": ["2", 0],
            "end_image": ["3", 0],
            "width": 576,  # å®‰å®šã—ãŸè§£åƒåº¦
            "height": 576,
            "length": 72,  # 3ç§’ (24fps Ã— 3)
            "batch_size": 1
        },
        "class_type": "WanFirstLastFrameToVideo"
    },
    "7": {
        "inputs": {
            "model": ["1", 0],
            "positive": ["6", 0],
            "negative": ["6", 1],
            "latent_image": ["6", 2],
            "seed": seed,
            "steps": 10,  # ã‚ˆã‚Šå¤šãã®ã‚¹ãƒ†ãƒƒãƒ—ã§å“è³ªå‘ä¸Š
            "cfg": 2.5,  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®å¿ å®Ÿåº¦ã‚’ä¸Šã’ã‚‹
            "sampler_name": "lcm",
            "scheduler": "beta",
            "denoise": 1.0
        },
        "class_type": "KSampler"
    },
    "8": {
        "inputs": {
            "samples": ["7", 0],
            "vae": ["1", 2]
        },
        "class_type": "VAEDecode"
    },
    "9": {
        "inputs": {
            "images": ["8", 0],
            "filename_prefix": f"morph_3sec_{seed}"
        },
        "class_type": "SaveImage"
    }
}

print("\nğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€ä¿¡ä¸­...")
print(f"  è§£åƒåº¦: 576Ã—576")
print(f"  é•·ã•: 3ç§’ (72ãƒ•ãƒ¬ãƒ¼ãƒ )")
print(f"  å“è³ª: é«˜ (10ã‚¹ãƒ†ãƒƒãƒ—)")
print("  åŠ¹æœ: ã‚†ã£ãã‚Šã¨ã—ãŸäººç‰©å¤‰åŒ–")

response = requests.post(f"{COMFYUI_URL}/prompt", json={"prompt": workflow})
result = response.json()

prompt_id = result.get("prompt_id")
if not prompt_id:
    print(f"âŒ Failed: {result}")
    exit(1)

print(f"\nğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆID: {prompt_id}")
print("â³ å‡¦ç†ä¸­ï¼ˆç´„1-2åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰...")

# Wait for completion
start_time = time.time()
dots = 0
while time.time() - start_time < 180:  # 3åˆ†ã¾ã§å¾…ã¤
    history = requests.get(f"{COMFYUI_URL}/history/{prompt_id}").json()
    
    if prompt_id in history:
        if "outputs" in history[prompt_id]:
            elapsed = time.time()-start_time
            print(f"\n\nâœ… ç”Ÿæˆå®Œäº†ï¼")
            print(f"â±ï¸ å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’")
            
            outputs = history[prompt_id]["outputs"]
            images = []
            for node_id, output in outputs.items():
                if "images" in output:
                    for img in output["images"]:
                        images.append(img['filename'])
            
            if images:
                print(f"ğŸ“¹ ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(images)}")
                
                # Create video
                output_dir = "/home/kazuph/runpod-wan2.2-api/comfyui_workflow/output"
                video_output = f"/home/kazuph/runpod-wan2.2-api/flf/output/morph_3sec_{seed}.mp4"
                
                # Use first image name pattern
                pattern = images[0].replace("00001", "%05d")
                
                cmd = f"ffmpeg -framerate 24 -pattern_type sequence -start_number 1 -i '{output_dir}/{pattern}' -c:v libx264 -pix_fmt yuv420p -crf 19 {video_output} -y 2>/dev/null"
                
                if os.system(cmd) == 0:
                    if os.path.exists(video_output):
                        size_kb = os.path.getsize(video_output) / 1024
                        print(f"\nğŸ‰ 3ç§’ãƒ¢ãƒ¼ãƒ•ã‚£ãƒ³ã‚°å‹•ç”»ç”ŸæˆæˆåŠŸï¼")
                        print(f"ğŸ“ ä¿å­˜å…ˆ: {video_output}")
                        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size_kb:.1f} KB")
                        print(f"ğŸ¬ å†…å®¹: girl1ã‹ã‚‰girl2ã¸3ç§’ã‹ã‘ã¦ã‚†ã£ãã‚Šå¤‰åŒ–")
                    else:
                        print(f"âš ï¸ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                else:
                    print(f"âš ï¸ ffmpegå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™: {output_dir}/{images[0]}")
            
            exit(0)
        
        if "status" in history[prompt_id]:
            status = history[prompt_id]["status"]
            if status.get("status_str") == "error":
                print(f"\nâŒ Error: {status}")
                exit(1)
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
    dots = (dots + 1) % 4
    progress = "." * dots + " " * (3 - dots)
    print(f"\râ³ å‡¦ç†ä¸­{progress} ({int(time.time()-start_time)}ç§’çµŒé)", end="", flush=True)
    time.sleep(2)

print("\nâŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ3åˆ†çµŒéï¼‰")
exit(1)